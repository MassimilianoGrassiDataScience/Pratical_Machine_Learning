{
    "contents" : "---\n\nauthor: \"Massimiliano Grassi\"\ndate: \"19 maggio 2015\"\noutput:\n  html_document:\n    keep_md: yes\n---\n\n#Pratical Machine Learning. Course Project: Writeup\n\nThe data for this project come from [this source](http://groupware.les.inf.puc-rio.br/har).\n\nThe datasets contain data from accelerometers worn by people that perfored several Dumbbell Bicep Curl exercises in five different ways: one (A) following the correct technique and four (B-E) with incorrect techniques. The training dataset contains data from `r nrow(training)` observations with the correct classification in the factor variable 'classe'. The testing set contains 20 observation not included in the training dataset that the built algorhitm will have to predict (the correct classification is not provided in the test dataset). \n\n```{r, warning=FALSE, message=FALSE, cache=TRUE}\ndir.create(\"./data\")\ndownload.file(\"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\", destfile = \"./data/training.csv\")\n\ndownload.file(\"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\", destfile=\"./data/testing.csv\")\n\ntraining<-read.csv(\"./data/training.csv\")\ntesting<-read.csv(\"./data/testing.csv\")\n```\n\n##Model Training\n\nThe original training data set was split in a train (80%) and a validation (20%) dataset, in order to use the latter to have an unbiased estimate of the out-of-sample classification performance.\n\n```{r, cache=TRUE, message=FALSE}\nlibrary('caret')\n\ntrain_validation_split  <- createDataPartition(training$classe, p=0.8, list = FALSE)\ntrain  <- training[train_validation_split,]\nvalidation  <- training[-train_validation_split,]\n```\n\nVariable not of interest were removed from the train dataset, e.g. those regarding subjects name and time-stamps or those including mostly missing values. A summary of the removed variables is reported in Appendix 1.\n\n```{r, cache=TRUE}\ntrain_cleaned<-train[,-c(1:7,12:36,50:59,69:83,87:101,103:112,125:139,141:150)]\n```\n\nAll the remaining variables will be employed as cadidate predictors in the process of model building and training. They are all numeric, as indentified by a variable inspection (see Appendix 2). \n\nRandom Forest was chosen as algorithm to build the predicitive model. Training was performed with the train function in the caret package. A k-fold cross-validation strategy (k=20) was be applied during the training in order to choose the combination of tuning parameters that provides the best performance. After that the best tuning parameters combination was identified, the final model was trained with this combination applying the entire train sample.\n\n```{r, cache=TRUE}\ncross_validation  <- trainControl(method = 'cv', number = 20)\n\nModel_Random_Forest  <- train(classe ~., method = 'rf', data=train_cleaned, trControl = cross_validation)\n\nprint(Model_Random_Forest)\n```\n\n#Model Testing\n\nTo have an estemation of the out-of-sample classification performance, the fitted model was applied to the validation dataset.\n\n```{r, cache=TRUE}\nResult_Validation  <- predict(Model_Random_Forest, validation)\nconfusionmatrixValidation  <- confusionMatrix(Result_Validation, validation$classe)\nprint(confusionmatrixValidation)\n```\n\nThe estimated out-of-sample classification accuracy is `r confusionmatrixValidation[[3]][1]*100`% and kappa is `r confusionmatrixValidation[[3]][2]`, while the estimated classification error is `r (1-confusionmatrixValidation[[3]][1])*100`%, as calculated in the validation sample not used to build the madel. \n\n##Prediction performed with testing dataset\n\nFinally, the model was applied to the testing set and predictions were saved as individual text-files as required for the sumbission to the Coursera web-site.\n\n\n```{r, warning=FALSE, cache=TRUE}\nResult_Testing  <- as.character(predict(Model_Random_Forest, testing))\n\npml_write_files = function(x){\n  n = length(x)\n  for(i in 1:n){\n    filename = paste0(\"problem_id_\",i,\".txt\")\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\n  }\n}\n\ndir.create(\"./testing_results\")\nsetwd(\"./testing_results\")\n\npml_write_files(Result_Testing)\n```\n\n##Appendix \n##1.\n```{r, cache=TRUE}\nsummary(train[,c(1:7,12:36,50:59,69:83,87:101,103:112,125:139,141:150)])\n```\n\n##2.\n```{r, cache=TRUE}\nsummary(train_cleaned)\n```\n\n",
    "created" : 1432037353064.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1052431507",
    "id" : "EE9B5996",
    "lastKnownWriteTime" : 1432130359,
    "path" : "~/GIT/Machine_Learning/Lift.Rmd",
    "project_path" : "Lift.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}